{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import keras\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library versions should be used:\n",
    "keras = 2.3.1\n",
    "numpy = 1.17.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"D:/Sun'iyX/Data/Pictured\"\n",
    "outputmodel = r\"D:\\Sun'iyX\\ML\\VideoClsfImgbased\\ContentTypeClassifier\\video_classification_model\\videoclassificationModel\"\n",
    "outputlabelbinarizer = r\"D:\\Sun'iyX\\ML\\VideoClsfImgbased\\ContentTypeClassifier\\model\\videoclassificationbinarizer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images are being loaded ...\n"
     ]
    }
   ],
   "source": [
    "media_labels = set(['Ad','Content'])\n",
    "print(\"images are being loaded ...\")\n",
    " \n",
    "pathToImages = list(paths.list_images(datapath))\n",
    "\n",
    "data = []\n",
    "\n",
    "labels = []\n",
    "\n",
    "for images in pathToImages:\n",
    "    label = images.split(os.path.sep)[-2]\n",
    "    if label not in media_labels:\n",
    "        continue\n",
    "    image = cv2.imread(images)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (244,244))\n",
    "    data.append(image)\n",
    "    labels.append(label)\n",
    "        \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(data, labels, test_size = 0.25, stratify=labels, random_state=42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingAugmentation = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    "    \n",
    ")\n",
    "\n",
    "validationAugmentation = ImageDataGenerator()\n",
    "mean = np.array([123.68, 166.779, 103.939], dtype=\"float32\")\n",
    "trainingAugmentation.mean = mean\n",
    "validationAugmentation.mean = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.layers.pooling import AveragePooling2D\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "\n",
    "from keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModel = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(224,244,3)))\n",
    "\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7,7))(headModel)\n",
    "headModel = Flatten(name = \"Flatten\")(headModel)\n",
    "headModel = Dense(512, activation='relu')(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(len(lb.classes_), activation='sigmoid')(headModel) # activation function changed from softmax to sigmoid \n",
    "model = Model(inputs = baseModel.input, outputs = headModel)\n",
    "\n",
    "for baseModelLayers in baseModel.layers:   \n",
    "       \n",
    "    baseModelLayers.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 25\n",
    "# opt = SGD(lr = 0.0001, momentum=0.9, decay = 0.0001/epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics=['accuracy']) # optimizer changed to adam instead of opt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER1\\AppData\\Local\\Temp\\ipykernel_2940\\2583291714.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  History = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "49/49 [==============================] - 68s 1s/step - loss: 0.0105 - accuracy: 0.9949\n",
      "Epoch 2/25\n",
      "49/49 [==============================] - 65s 1s/step - loss: 3.1756e-16 - accuracy: 1.0000\n",
      "Epoch 3/25\n",
      "49/49 [==============================] - 65s 1s/step - loss: 6.4528e-14 - accuracy: 1.0000\n",
      "Epoch 4/25\n",
      "49/49 [==============================] - 66s 1s/step - loss: 1.4991e-17 - accuracy: 1.0000\n",
      "Epoch 5/25\n",
      "49/49 [==============================] - 69s 1s/step - loss: 8.9393e-18 - accuracy: 1.0000\n",
      "Epoch 6/25\n",
      "49/49 [==============================] - 68s 1s/step - loss: 7.3574e-18 - accuracy: 1.0000\n",
      "Epoch 7/25\n",
      "49/49 [==============================] - 66s 1s/step - loss: 2.3710e-16 - accuracy: 1.0000\n",
      "Epoch 8/25\n",
      "49/49 [==============================] - 68s 1s/step - loss: 1.0059e-16 - accuracy: 1.0000\n",
      "Epoch 9/25\n",
      "49/49 [==============================] - 65s 1s/step - loss: 1.9237e-15 - accuracy: 1.0000\n",
      "Epoch 10/25\n",
      "49/49 [==============================] - 65s 1s/step - loss: 6.4432e-17 - accuracy: 1.0000\n",
      "Epoch 11/25\n",
      "49/49 [==============================] - 69s 1s/step - loss: 1.8518e-15 - accuracy: 1.0000\n",
      "Epoch 12/25\n",
      "49/49 [==============================] - 67s 1s/step - loss: 3.8569e-17 - accuracy: 1.0000\n",
      "Epoch 13/25\n",
      "49/49 [==============================] - 66s 1s/step - loss: 1.0322e-16 - accuracy: 1.0000\n",
      "Epoch 14/25\n",
      "49/49 [==============================] - 64s 1s/step - loss: 1.4325e-16 - accuracy: 1.0000\n",
      "Epoch 15/25\n",
      "49/49 [==============================] - 67s 1s/step - loss: 8.9500e-16 - accuracy: 1.0000\n",
      "Epoch 16/25\n",
      "49/49 [==============================] - 92s 2s/step - loss: 1.1202e-16 - accuracy: 1.0000 - val_loss: 1.9301e-17 - val_accuracy: 1.0000\n",
      "Epoch 17/25\n",
      "49/49 [==============================] - 66s 1s/step - loss: 7.1095e-18 - accuracy: 1.0000\n",
      "Epoch 18/25\n",
      "49/49 [==============================] - 66s 1s/step - loss: 1.8957e-17 - accuracy: 1.0000\n",
      "Epoch 19/25\n",
      "49/49 [==============================] - 66s 1s/step - loss: 2.9181e-16 - accuracy: 1.0000\n",
      "Epoch 20/25\n",
      "49/49 [==============================] - 66s 1s/step - loss: 5.8095e-19 - accuracy: 1.0000\n",
      "Epoch 21/25\n",
      "49/49 [==============================] - 66s 1s/step - loss: 4.6256e-15 - accuracy: 1.0000\n",
      "Epoch 22/25\n",
      "49/49 [==============================] - 66s 1s/step - loss: 5.5808e-19 - accuracy: 1.0000\n",
      "Epoch 23/25\n",
      "49/49 [==============================] - 66s 1s/step - loss: 3.0622e-16 - accuracy: 1.0000\n",
      "Epoch 24/25\n",
      "49/49 [==============================] - 68s 1s/step - loss: 1.5243e-16 - accuracy: 1.0000\n",
      "Epoch 25/25\n",
      "49/49 [==============================] - 65s 1s/step - loss: 1.8137e-16 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "History = model.fit_generator(\n",
    "    trainingAugmentation.flow(X_train, Y_train, batch_size=32),\n",
    "    steps_per_epoch=len(X_train)//32,\n",
    "    validation_data= validationAugmentation.flow(X_test, Y_test),\n",
    "    validation_freq=len(X_test)//32,\n",
    "    epochs=epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\Sun'iyX\\ML\\VideoClsfImgbased\\ContentTypeClassifier\\video_classification_model\\videoclassificationModel\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\Sun'iyX\\ML\\VideoClsfImgbased\\ContentTypeClassifier\\video_classification_model\\videoclassificationModel\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(outputmodel)\n",
    "lbinarizer = open(r\"D:\\Sun'iyX\\ML\\VideoClsfImgbased\\ContentTypeClassifier\\model\\classificationbinarizer.pickle\", \"wb\")\n",
    "lbinarizer.write(pickle.dumps(lb))\n",
    "lbinarizer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CNN3D",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
